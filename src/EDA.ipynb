{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: DataCo SMART SUPPLY CHAIN FOR BIG DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Essential Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries specialized \"expert kits\" to plug into Python essential for EDA.\n",
    "import os, json, math, joblib, requests\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy._core.defchararray import upper\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle # -- Binary (unreadable by humans) -- Can save almost any Python object -- Very fast for complex objects --\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, f_regression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_absolute_error, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, RidgeCV, LassoCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Problem Statement / Data Collection\n",
    "## 2.1 Description of the Problem\n",
    "----------------- TBC --------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Inicitial Loading and Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Johnny's Safety Reset\n",
    "db_name = \"supply_chain_logistics.db\"\n",
    "if os.path.exists(db_name):\n",
    "    os.remove(db_name)\n",
    "    print(f\"Cleanup: Old {db_name} removed.\")\n",
    "\n",
    "# 2. Francisco's Clean Loading (DataCo specific)\n",
    "# Note: Using latin1 encoding as required for this specific raw file\n",
    "df = pd.read_csv('../data/raw/DataCoSupplyChainDataset.csv', encoding='latin1')\n",
    "\n",
    "# Clean column names (removing spaces and special characters for SQL compatibility)\n",
    "df.columns = [c.replace(' ', '_').replace('(', '').replace(')', '').replace('.', '') for c in df.columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Store the Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create fresh Engine and Table\n",
    "engine = create_engine(f'sqlite:///{db_name}')\n",
    "# 4. Define dataset variable through SQL\n",
    "df.to_sql('supply_chain', engine, if_exists='replace', index=False)\n",
    "print(f\"Success! DataCo dataset loaded into a fresh SQL table. Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Perform Descriptive Analysis\n",
    "## 4.1 Data Dimensions & Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic shape and info\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(\"\\nColumn Types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Verifying the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 5 rows for dataset columns and data visibility\n",
    "check_query = \"\"\" SELECT * FROM supply_chain\"\"\"\n",
    "df_supply = pd.read_sql(check_query, engine)\n",
    "print(tabulate(df_supply.head(), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how the Shipping mode affects on late delivery risk\n",
    "check_query = \"\"\"\n",
    "SELECT \n",
    "    Shipping_Mode,\n",
    "    COUNT(*) as total_orders,\n",
    "    ROUND(AVG(Late_delivery_risk), 3) as late_risk_rate,\n",
    "    ROUND(AVG(Days_for_shipping_real), 2) as avg_actual_days\n",
    "FROM supply_chain\n",
    "GROUP BY Shipping_Mode\n",
    "ORDER BY late_risk_rate DESC;\n",
    "\"\"\"\n",
    "df_results = pd.read_sql(check_query, engine)\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Conclusion on Shippin Mode Difference\n",
    "- We can confirm that Late_risk_rate ranges from 38% to 95%.\n",
    "------------------------------------\n",
    "Days Shippment Schedule:\n",
    "| Shipping Mode | Schedule Days |\n",
    "| --- | --- |\n",
    "| **First Class** | 1 |\n",
    "| **Second Class** | 2 |\n",
    "| **Same Day** | 0 |\n",
    "| **Standard Class** | 4 |\n",
    "\n",
    "--------------------------------------------------------------------------------\n",
    "\n",
    "| Shipping Mode | Risk Level | Avg. days | Comments |\n",
    "| --- | --- | --- | --- |\n",
    "| **First Class** | Very High | 2.00 | Unrealistic commitment on real days |\n",
    "| **Second Class** | High | 3.99 | Significant delays |\n",
    "| **Same Day** | Moderate | 0.48 | Highest delivery efficiency |\n",
    "| **Standard Class** | Low | 4.00 | Easier delivery to commit |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Numerical Summary (The \"Stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Statistical summary of key numerical columns\n",
    "important_cols = ['Sales', 'Sales_per_customer', 'Late_delivery_risk', 'Days_for_shipping_real', 'Order_Item_Discount_Rate', 'Benefit_per_order']\n",
    "desc_stats = df_supply[important_cols].describe()\n",
    "\n",
    "# 2. Get the Mode for categorical predictors\n",
    "categorical_cols = ['Shipping_Mode', 'Order_Region', 'Category_Name']\n",
    "modes = df_supply[categorical_cols].mode().iloc[0]\n",
    "\n",
    "print(\"--- Numerical Descriptive Stats ---\")\n",
    "print(tabulate(desc_stats, headers= \"keys\", tablefmt= \"psql\"))\n",
    "print(\"\\n--- Categorical Modes ---\")\n",
    "print(modes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Perform a full EDA\n",
    "## 5.1 Data Types and Non-Nulls Values Overview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"This is the information about Non-Null and Dtype:\\n================================================\")\n",
    "df_supply.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Conclusion on Non-Nulls\n",
    "1. The Missing Values (The \"Small Gaps\")\n",
    "we have a few missing entries:\n",
    "    - **Customer_Lname**: 8 missing values.\n",
    "    - **Customer_Zipcode**: 3 missing values.\n",
    "    - **Verdict**: Since these are so few, we can reviwe later if we could fill them with \"Unknown\" or 0 without hurting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Check Unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"These are the Unique Values for each columns on the Dataset:\\n============================================================\")\n",
    "print(df_supply.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Check for Duplicates Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are no identifiers, duplicate check looked at the entire row.\n",
    "duplicate_val = df_supply.duplicated().sum()\n",
    "print(f\"<< {duplicate_val} >> duplicated value in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Duplicates Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicates is a vital cleaning step.\n",
    "duplicate_rows = df_supply[df_supply.duplicated(keep= False)]\n",
    "print(\"Table with duplicates rows (in case they are and only for visibility):\\n======================================================\")\n",
    "print(tabulate(duplicate_rows.head(24), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will execute the code below to garantee no duplicates on the data set\n",
    "df_supply = df_supply.drop_duplicates().reset_index(drop= True)\n",
    "print(df_supply.shape)\n",
    "print(tabulate(df_supply.head(), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Eliminate Irrelevant Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have categorized the columns we should eliminate into three \"Noise\" groups:\n",
    "1. Administrative IDs: Unique numbers that don't repeat (like Order_Id).\n",
    "2. Redundant Identifiers: For instance, we have Category_Id and Category_Name; we only need the name (or the ID) for the model, not both.\n",
    "3. Sensitive/PII Data: Emails and passwords have zero predictive power for logistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column tha don't provide value for predicting delays\n",
    "cols_to_drop = ['Category_Id', 'Customer_Email', 'Customer_Fname', \n",
    "                'Customer_Id', 'Customer_Lname', 'Customer_Password', \n",
    "                'Customer_Street', 'Department_Id', 'Order_Customer_Id', \n",
    "                'Order_Id', 'Order_Item_Cardprod_Id', 'Order_Item_Id', \n",
    "                'Order_Zipcode', 'Product_Card_Id', 'Product_Image', \n",
    "                'Product_Description', 'Product_Status', 'order_date_DateOrders', \n",
    "                'Product_Category_Id', 'Order_Item_Cardprod_Id']\n",
    "\n",
    "# Code to drop the columns\n",
    "df_supply = df_supply.drop(columns= cols_to_drop)\n",
    "print(f\"Columns Removed: {len(cols_to_drop)}\")\n",
    "print(f\"Remaining Columns: {df_supply.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Checking Hidden Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Check for 'Hidden' missing values\n",
    "# Columns where a 0 is or could be impossible\n",
    "cols_to_fix = df_supply.columns\n",
    "\n",
    "print(\"Zero counts per column:\")\n",
    "for col in cols_to_fix:\n",
    "    print(f\"{col}: {(df_supply[col] == 0).sum()} zeros\")\n",
    "\n",
    "# 2. Visualize the Class Imbalance (Late_delivery_risk)\n",
    "target = 'Late_delivery_risk'\n",
    "plt.figure(figsize= (8,6))\n",
    "ax = sns.countplot(x= target, data= df_supply, hue= target, palette= 'viridis')\n",
    "plt.title('Distribution of Late Delivery Risk')\n",
    "plt.xlabel('Risk (0 = On-time, 1 = Late)')\n",
    "plt.ylabel('Total Number of Orders')\n",
    "\n",
    "# Adding the exact count on top of bars\n",
    "for x in ax.patches:\n",
    "    ax.annotate(f'{int(x.get_height())}', (x.get_x() + x.get_width() / 2., x.get_height()), \n",
    "                ha= 'center', va= 'baseline', fontsize= 12, color= 'black', xytext= (0, 5),\n",
    "                textcoords= 'offset points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.7.1 Conclusion on Hidden Values (those zeros) & Imbalance Target Chart\n",
    "1. The \"Natural\" Zeros (Safe to keep)\n",
    "These zeros make perfect sense in a business context:\n",
    "    - Late_delivery_risk (81,542): These are just the orders that were on time.\n",
    "    - Order_Item_Discount & Rate (10,028): These represent orders where no discount was applied.\n",
    "2. The Warning Zeros (Investigate or Drop)\n",
    "These are the ones that require your attention:\n",
    "    - Product_Status (180,519): Every single row is 0. This column provides zero information (zero variance). We should drop this immediately as it's a \"dead\" column.\n",
    "    - Days_for_shipping_real (5,080): A zero here implies the item was delivered the same day it was ordered.\n",
    "        - Check: Cross the reference this with Shipping_Mode == 'Same Day'. If they match, the zeros are real.\n",
    "    - Benefit_per_order / Order_Profit_Per_Order (1,177): These are orders where the company made exactly $0.00 profit. This is possible (break-even).\n",
    "3. The Suspicious Zeros\n",
    "    - Days_for_shipment_scheduled (9,737): This likely represents \"Express\" or \"Same Day\" shipping. Maybe the delivery was in a milk-run at a local area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.8 Categoric Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Convert the object column to a proper datetime format\n",
    "df_supply['shipping_date_DateOrders'] = pd.to_datetime(df_supply['shipping_date_DateOrders'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Only columns with object or str data type (categoric)\n",
    "categorics = df_supply.select_dtypes(include= ['object','string']).columns.tolist()\n",
    "print(f\"Categorics variables: {categorics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set up the grid\n",
    "n_cols = 3\n",
    "n_rows = math.ceil(len(categorics) / n_cols)\n",
    "fig, axis = plt.subplots(n_rows, n_cols, figsize= (18, 6 * n_rows))\n",
    "axis = axis.flatten()\n",
    "\n",
    "# 2. Integrate plots with automatic logic\n",
    "for i, col in enumerate(categorics):\n",
    "    # Plotting\n",
    "    sns.histplot(ax= axis[i], data= df_supply, x= col, color= 'skyblue')\n",
    "\n",
    "    axis[i].set_title(f'Raw Histplot of {col}', fontsize= 14)\n",
    "    axis[i].set_xlabel('')\n",
    "\n",
    "    # Hide the X labels if there are more than 20 values\n",
    "    if df_supply[col].nunique() > 25:\n",
    "        axis[i].set_xticks([])                          \n",
    "        axis[i].set_xlabel(f\"{df_supply[col].nunique()} unique values\")\n",
    "    else:\n",
    "        axis[i].tick_params(axis= 'x', rotation= 45)\n",
    "\n",
    "# Remove extra empty plot or grid\n",
    "for j in range(len(categorics), len(axis)):\n",
    "    fig.delaxes(axis[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. We have converted the object column to a proper datetime format above\n",
    "# 2. Extract new features\n",
    "df_supply['shipping_day'] = df_supply['shipping_date_DateOrders'].dt.day_name()\n",
    "df_supply['shipping_month'] = df_supply['shipping_date_DateOrders'].dt.month_name()\n",
    "df_supply['shipping_hour'] = df_supply['shipping_date_DateOrders'].dt.hour\n",
    "\n",
    "# 3. Plot the new clean distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.countplot(ax= axes[0], data= df_supply, x= 'shipping_day', color= 'skyblue',\n",
    "              order= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "axes[0].set_title('Orders by Day of Week')\n",
    "axes[0].tick_params(axis= 'x', rotation= 45)\n",
    "\n",
    "sns.countplot(ax= axes[1], data= df_supply, x= 'shipping_month', color= 'skyblue',)\n",
    "axes[1].set_title('Orders by Month')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "sns.countplot(ax= axes[2], data= df_supply, x= 'shipping_hour', color= 'skyblue',)\n",
    "axes[2].set_title('Orders by Hour of Day')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8.1 Conclusions for Categorical Variable Charts\n",
    "------------------ TBC ------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Numeric Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only columns with 'int or float' data type (numeric)\n",
    "numerics = df_supply.select_dtypes(include= ['number']).columns.tolist()\n",
    "print(f\"Numeric variables: {numerics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating histplot and boxplot for the numeric variables\n",
    "if len(numerics) != 0:\n",
    "    nrows = len(numerics)\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows= nrows, ncols= ncols, figsize=(15, 4 * nrows))\n",
    "\n",
    "    for i, col in enumerate(numerics):\n",
    "        sns.histplot(df_supply[col], kde= True, ax= axes[i, 0], color= \"skyblue\")\n",
    "        axes[i, 0].set_title(f'Histogram of {col}')\n",
    "        sns.boxplot(x= df_supply[col], ax= axes[i, 1], color= \"salmon\")\n",
    "        axes[i, 1].set_title(f'Boxplot of {col}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"There are no numercial variables or the list numerics might be empty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.8.1 Conclusions for Numerical Variable Charts\n",
    "We want to share only key observations on the charts.\n",
    "- **The \"Gap\" Distributions**: Days_for_shipping_real vs. Days_for_shipment_scheduled. Notice how the scheduled days have very specific \"peaks\" (discrete values), while the real days are more spread out.\n",
    "- **The Profit Outliers**: The boxplot for Benefit_per_order and Order_Profit_Per_Order shows a very long \"tail\" of dots on the left side. They are extreme points that the model should help investigate.\n",
    "- **The Skewed Revenue**: The Sales and Sales_per_customer histograms show a sharp peak on the left with a long tail to the right.\n",
    "- **The Balanced Target**: The separate count plot for Late_delivery_risk is beautiful. It clearly shows the class balance, which is the \"green light\" to proceed with standard ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.9 Categorical-Categorical Analysis (Multivariate Variables Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical including the new features\n",
    "# Excluding the raw shipping_date sice we transformed it\n",
    "cols_to_plot = [c for c in categorics if c != 'shipping_date_DateOrders'] +  \\\n",
    "               ['shipping_day', 'shipping_month', 'shipping_hour']\n",
    "# 1. Set up Grid\n",
    "n_cols = 2\n",
    "n_rows = math.ceil(len(cols_to_plot) / n_cols)\n",
    "fig, axis = plt.subplots(n_rows, n_cols, figsize= (20, 6 * n_rows))\n",
    "axis = axis.flatten()\n",
    "\n",
    "# 2. Loop through the columns and plot with the 'Late_delivery_risk' class as hue\n",
    "for i, col in enumerate(cols_to_plot):\n",
    "    # For high cardinality columns, only plot the top 10 to keep it readable\n",
    "    if df_supply[col].nunique() > 10:\n",
    "        top_10 = df_supply[col].value_counts().nlargest(10).index\n",
    "        plot_data = df_supply[df_supply[col].isin(top_10)]\n",
    "        title_suffix = \"(Top 10)\"\n",
    "    else:\n",
    "        plot_data = df_supply\n",
    "        title_suffix = \"\"\n",
    "\n",
    "    # Plotting with bars sorted by total count for better readability\n",
    "    order = plot_data[col].value_counts().index\n",
    "    sns.countplot(ax= axis[i], data= plot_data, x= col, hue= 'Late_delivery_risk', palette= 'viridis', order= order)\n",
    "    axis[i].set_title(f'{col} vs. Late Delivery Risk{title_suffix}')\n",
    "    axis[i].set_xlabel('')\n",
    "    axis[i].legend(title= 'Risk 1= Late', loc= 'upper right')\n",
    "    axis[i].tick_params(axis= 'x', rotation= 45)\n",
    "\n",
    "# 3. Final clean up of the grid\n",
    "for j in range(len(cols_to_plot), len(axis)):\n",
    "    fig.delaxes(axis[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.9.1 Conclusion Cat - Cat Analysis\n",
    "- **Type vs. Risk**: \"DEBIT\" and \"TRANSFER\" payments seem to have a higher volume of late deliveries compared to \"CASH\" or \"PAYMENT\"\n",
    "- **Delivery Status vs. Risk**: We can see that the \"Late Delivery\" is 100% late and there is no blue bar. This is Delivery_Status is a duplicate of Late_delivery_risk.\n",
    "- **Category_Name vs Risk**: High volume items like **Cleats**, **Men's Footwear**, and **Women's Apparel** dominate the late delivery counts.\n",
    "- **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.10 Numerical-Numerical Analysis (Multivariate Variables Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Excluding the target. The condition is to avoid ploting the target with itself.\n",
    "if 'Late_delivery_risk' in numerics: numerics.remove('Late_delivery_risk')\n",
    "target_num = 'Late_delivery_risk'\n",
    "\n",
    "# 2. Calculate Grid Size\n",
    "ncols = 3\n",
    "group_chart = math.ceil(len(numerics) / ncols)\n",
    "nrows = group_chart * 2 # Double the rows (one for Reg, one for Heatmap)\n",
    "\n",
    "fig, axes = plt.subplots(nrows= nrows, ncols= ncols, figsize= (18, 4 * nrows))\n",
    "\n",
    "for chart_idx in range(group_chart):\n",
    "    # Determine which row we are on for Regplots\n",
    "    reg_row = chart_idx * 2\n",
    "    # The Heatmap row is always the one right below it\n",
    "    heat_row = reg_row + 1\n",
    "\n",
    "    # Get the 3 variables for this group\n",
    "    start = chart_idx * ncols\n",
    "    end = start + ncols\n",
    "    current_vars = numerics[start:end]\n",
    "\n",
    "    for col_idx, col in enumerate(current_vars):\n",
    "        # --- Plot 1: Regplot ---\n",
    "        sns.regplot(data= df_supply, x= col, y= target_num, ax= axes[reg_row, col_idx], scatter_kws= {'alpha':0.05}, line_kws= {'color':'red'})\n",
    "        axes[reg_row, col_idx].set_title(f'Regplot: {col}')\n",
    "        if col_idx > 0:\n",
    "            axes[reg_row, col_idx].set(ylabel= None)\n",
    "        # --- Plot 2: Heatmap ---\n",
    "        sns.heatmap(df_supply[[col, target_num]].corr(), annot= True, fmt= \".2f\", ax= axes[heat_row, col_idx], cmap= 'coolwarm', cbar= False)\n",
    "        axes[heat_row, col_idx].set_title(f'Corr: {col}')\n",
    "# 4. Hide empty slots (if any)\n",
    "for col_idx in range(len(current_vars), ncols):\n",
    "    axes[reg_row, col_idx].set_visible(False)\n",
    "    axes[heat_row, col_idx].set_visible(False)\n",
    "\n",
    "\n",
    "plt.tight_layout(pad= 3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.10.1 Num - Num Conclusion\n",
    "* Let's see what those charts are telling us about thouse features or variables.\n",
    "1. **The Logic Predictors: Shipping Days**\n",
    "    - **Observation**: Days_for_shipping_real shows a nearly perfect positive correlation with the target. As actual shipping time increases, the risk of a late delivery becomes a certainty.\n",
    "    - **Observation**: Days_for_shipment_scheduled shows a negative correlation. This indicates that orders with more generous planned delivery windows are significantly less likely to result in a late status.\n",
    "2. **The Financial Indicators: Profit & Sales**\n",
    "    - **Observation**: Benefit_per_order and Sales show very flat regression lines. This means that whether an order is highly profitable or a high-revenue sale, it doesn't necessarily change the probability of it being late.\n",
    "    - **Observation**: The distribution of Benefit_per_order contains extreme negative outliers (losses over $4,000), suggesting that while profit doesn't predict lateness, lateness might be causing these financial cost impact.\n",
    "3. **Geographical & Order Metrics**\n",
    "    - **Observation**: Latitude, Longitude, and Order_Item_Quantity show near-zero correlation with Late_delivery_risk.\n",
    "    - **Insight**: The physical location of the customer or the size of the order (quantity) are not the primary drivers of delays in this specific supply chain.\n",
    "\n",
    "* **Decision for Modeling**:\n",
    "- We must exclude Days_for_shipping_real from the training features to avoid Data Leakage, as this value is only known after the event has occurred.\n",
    "- We should focus on Days_for_shipment_scheduled, Shipping_Mode, and Order_Region as our primary predictors.\n",
    "- The presence of extreme outliers in Benefit_per_order justifies our previous decision to handle high-earners/outliers separately to prevent model distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.11 Num - Num Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating heatmap chart to analyze complete variables correlation\n",
    "cols_num = df_supply.select_dtypes(include= ['number']).columns.tolist()\n",
    "fig, ax = plt.subplots(figsize= (15, 9))\n",
    "sns.heatmap(df_supply[cols_num].corr(method= \"pearson\"), annot= True, fmt= \".2f\", cmap= \"coolwarm\", ax= ax).tick_params(axis= 'x', rotation= 90)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.11.1 Conclusion Correlation Heatmap\n",
    "\n",
    "* Let’s review the information from our correlation chart and draw some conclusions:\n",
    "\n",
    "    1. **Correlations of 0.99 – 1.00:**  \n",
    "        - Sales <-> Order_Item_Total (~0.99)  \n",
    "        - Sales <-> Sales_per_customer (~0.99)  \n",
    "        - Product_Price <-> Order_Item_Product_Price (~1.00)  \n",
    "        - Benefit_per_order <-> Order_Profit_Per_Order (~1.00)  \n",
    "        - Order_Item_Product_Price <-> Product_Price  \n",
    "        - Order_Item_Total <-> Sales_per_customer  \n",
    "\n",
    "    **Conclusion**: Redundant variables. In predictive models, this may cause multicollinearity.  \n",
    "    **Recommendation**: Remove one variable from each pair when modeling.  \n",
    "\n",
    "    2. **Strong Sales Relationship**:   \n",
    "\n",
    "        - Sales <-> Order_Item_Product_Price (~0.79)  \n",
    "        - Sales <-> Order_Item_Discount (~0.62)  \n",
    "        - Sales <-> Order_Item_Total (~1.00)  \n",
    "\n",
    "    **Conclusion**: Discounts show a positive correlation with sales; likely, when higher discounts are applied, sales volume increases.  \n",
    "  \n",
    "    3. **Shipping and Late Delivery Risk:**  \n",
    "\n",
    "        - Days_for_shipping_real <-> Days_for_shipment_scheduled (~0.52): Moderately correlated.  \n",
    "        - Days_for_shipping_real <-> Late_delivery_risk (~0.40): More actual shipping days increase the risk of delay.  \n",
    "        - Days_for_shipment_scheduled <-> Late_delivery_risk (-0.37): When the scheduled shipping time is longer, the risk decreases. This may indicate that planning with a larger time buffer reduces delays.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pairplot to have a variables behaviour visibility \n",
    "# 1. Select only the top variables that showed correlation or interest in the heatmap\n",
    "top_vars = ['Days_for_shipping_real', 'Sales', 'Sales_per_customer', 'Days_for_shipping_real', 'Benefit_per_order']\n",
    "# 2. Sample the data 2000 rows to make the pairplot more readable and faster to render\n",
    "df_supply_sample = df_supply.sample(n= 2000, random_state= 42)\n",
    "sns.pairplot(df_supply[top_vars], hue='Late_delivery_risk', palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Final DataSet Columns\n",
    "1. The \"Baseline\" Version (All Variables)\n",
    "    - To see how KNN performs when it has access to every single data point, even the \"noisy\" ones like Sugar and pH.\n",
    "    - **final_cols_base** = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality_bin']\n",
    "2. The \"Optimized\" Version (Dropping Noise/Redundancy)\n",
    "    - To see if accuracy increases when we remove Multicollinearity (Density/pH) and Low Correlation (Sugar).\n",
    "    - final_cols_opt = ['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'sulphates', 'alcohol', 'quality_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols_base = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality_bin']\n",
    "final_cols_opt = ['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'sulphates', 'alcohol', 'quality_bin']\n",
    "\n",
    "df_col_base = df[final_cols_base]\n",
    "df_col_opt = df[final_cols_opt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(df_col_base.describe(), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tabulate(df_col_opt.describe(), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Feature Engineering\n",
    "## 6.1 Outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating boxplot to understand the outliers in each variable\n",
    "ncols = 3\n",
    "nrows = math.ceil(len(final_cols_base) / ncols)\n",
    "fig, axes = plt.subplots(nrows= nrows, ncols= ncols, figsize= (15, 4 * nrows))\n",
    "\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(final_cols_base):\n",
    "    sns.boxplot(data= df_col_base, y= col, ax= axes[i], color= 'salmon')\n",
    "for j in range(len(final_cols_base), len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Conclusion Boxplots Charts\n",
    "- Those boxplots are the final \"green light\" we needed to proceed with the model. By visualizing the outliers so clearly, I’ve identified exactly where the KNN algorithm might get \"pulled\" in the wrong direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary coding to replace outliers creating upper and lower limits\n",
    "df_WITH_outliers_baseCol = df_col_base.copy()\n",
    "df_WITHOUT_outliers_baseCol = df_col_base.copy()\n",
    "\n",
    "df_WITH_outliers_optCol = df_col_opt.copy()\n",
    "df_WITHOUT_outliers_optCol = df_col_opt.copy()\n",
    "\n",
    "outliers_cols_base = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol'] # The target variable price can't be modified so we leave as it is.\n",
    "outliers_cols_opt = ['fixed acidity', 'volatile acidity', 'citric acid', 'chlorides', 'total sulfur dioxide', 'sulphates', 'alcohol']\n",
    "\n",
    "def replace_outliers(column, data_df):\n",
    "   col_stats = data_df[column].describe()\n",
    "   col_iqr = col_stats[\"75%\"] - col_stats[\"25%\"]\n",
    "   upper_limit = round(float(col_stats[\"75%\"] + 1.5 * col_iqr), 2)\n",
    "   lower_limit = round(float(col_stats[\"25%\"] - 1.5 * col_iqr), 2)\n",
    "\n",
    "   if lower_limit < 0: lower_limit = min(df[column])\n",
    "   # Let's take out upper outliers \n",
    "   data_df[column] = data_df[column].apply(lambda x: x if (x <= upper_limit) else upper_limit)\n",
    "   # Let's take out lower outliers \n",
    "   data_df[column] = data_df[column].apply(lambda x: x if (x >= lower_limit) else lower_limit)\n",
    "   return data_df.copy(), [lower_limit, upper_limit]\n",
    "\n",
    "outliers_dict_base = {}\n",
    "for column in outliers_cols_base:\n",
    "   df_WITHOUT_outliers_baseCol, limits = replace_outliers(column, df_WITHOUT_outliers_baseCol)\n",
    "   outliers_dict_base.update({column: limits})\n",
    "\n",
    "outliers_dict_opt= {}\n",
    "for column in outliers_cols_opt:\n",
    "   df_WITHOUT_outliers_optCol, limits = replace_outliers(column, df_WITHOUT_outliers_optCol)\n",
    "   outliers_dict_opt.update({column: limits})\n",
    "\n",
    "print(f\"Limits using base columns: {outliers_dict_base}\") # This jason needs to be saved\n",
    "print(f\"Limits using optimized columns: {outliers_dict_opt}\") # This jason needs to be saved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the json dictionary for outliers limit\n",
    "with open('../data/interim/outliers_dict_base.json', 'w') as f:\n",
    "     json.dump(outliers_dict_base, f)\n",
    "\n",
    "with open('../data/interim/outliers_dict_opt.json', 'w') as f:\n",
    "     json.dump(outliers_dict_opt, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The list below, will show if dataset WITH outliers has any null value for the variables:\")\n",
    "print(df_WITH_outliers_baseCol.isnull().sum().sort_values(ascending= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The list below, will show if dataset WITHOUT outliers has any null value for the variables:\")\n",
    "print(df_WITHOUT_outliers_baseCol.isnull().sum().sort_values(ascending= False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Inference of New Features\n",
    "* Proposed Engineering for Both Sets\n",
    "    - The Acidity Index: Create a total_acidity column ($fixed + volatile + citric$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_engineering(df_input, is_base= True):\n",
    "    \n",
    "    # Applied to both sets\n",
    "    df_input['total_acidity'] = df_input['fixed acidity'] + df_input['volatile acidity'] + df_input['citric acid']\n",
    "    \n",
    "    return df_input\n",
    "\n",
    "# Generate the new experimental sets\n",
    "df_WITH_outliers_baseCol = apply_engineering(df_WITH_outliers_baseCol, is_base=True)\n",
    "df_WITHOUT_outliers_baseCol = apply_engineering(df_WITHOUT_outliers_baseCol, is_base=True)\n",
    "\n",
    "df_WITH_outliers_optCol = apply_engineering(df_WITH_outliers_optCol, is_base=False)\n",
    "df_WITHOUT_outliers_optCol = apply_engineering(df_WITHOUT_outliers_optCol, is_base=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating << NEW >> heatmap chart to analyze complete variables correlation\n",
    "cols_num = df_WITH_outliers_baseCol.select_dtypes(include= ['number']).columns.tolist()\n",
    "fig, ax = plt.subplots(figsize= (15, 9))\n",
    "sns.heatmap(df_WITH_outliers_baseCol[cols_num].corr(method= \"pearson\"), annot= True, fmt= \".2f\", cmap= \"coolwarm\", ax= ax).tick_params(axis= 'x', rotation= 45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Conclusion on New Features\n",
    "1. The \"Total Acidity\" Stability\n",
    "- total_acidity feature shows a strong $1.00$ correlation with fixed acidity and $0.69$ with citric acid.\n",
    "    - The Strategy: This confirms that I can safely drop the three individual acid columns.\n",
    "\n",
    "* **Given the conclusion above**,\n",
    "    - **FINAL_COL_DATSET_BASE** = [total_acidity, residual sugar, total sulfur dioxide, chlorides, sulphates, alcohol, pH, density, quality_bin]\n",
    "    - **FINAL_COL_DATSET_OPT** = [total_acidity, total sulfur dioxide, chlorides, sulphates, alcohol, quality_bin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_COL_DATSET_BASE = ['total_acidity', 'residual sugar', 'total sulfur dioxide', 'chlorides', 'sulphates', 'alcohol', 'pH', 'density', 'quality_bin']\n",
    "FINAL_COL_DATSET_OPT = ['total_acidity', 'total sulfur dioxide', 'chlorides', 'sulphates', 'alcohol', 'quality_bin']\n",
    "\n",
    "df_WITH_outliers_baseCol = df_WITH_outliers_baseCol[FINAL_COL_DATSET_BASE]\n",
    "df_WITHOUT_outliers_baseCol = df_WITHOUT_outliers_baseCol[FINAL_COL_DATSET_BASE]\n",
    "df_WITH_outliers_optCol = df_WITH_outliers_optCol[FINAL_COL_DATSET_OPT]\n",
    "df_WITHOUT_outliers_optCol = df_WITHOUT_outliers_optCol[FINAL_COL_DATSET_OPT]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the set into train and test\n",
    "\t\t\t\t\n",
    "predictors_base = ['total_acidity', 'residual sugar', 'total sulfur dioxide', 'chlorides', 'sulphates', 'alcohol', 'pH', 'density']\n",
    "predictors_opt = ['total_acidity', 'total sulfur dioxide', 'chlorides', 'sulphates', 'alcohol']\n",
    "target = 'quality_bin'\n",
    "\n",
    "X_WITH_outliers_baseCol = df_WITH_outliers_baseCol.drop(target, axis = 1)[predictors_base]\n",
    "X_WITHOUT_outliers_baseCol = df_WITHOUT_outliers_baseCol.drop(target, axis = 1)[predictors_base]\n",
    "X_WITH_outliers_optCol = df_WITH_outliers_optCol.drop(target, axis= 1)[predictors_opt]\n",
    "X_WITHOUT_outliers_optCol = df_WITHOUT_outliers_optCol.drop(target, axis= 1)[predictors_opt]\n",
    "y = df_WITH_outliers_baseCol[target]\n",
    "\n",
    "X_train_WITH_outliers_baseCol, X_test_WITH_outliers_baseCol, y_train, y_test = train_test_split(X_WITH_outliers_baseCol, y, test_size = 0.2, random_state = 10)\n",
    "X_train_WITHOUT_outliers_baseCol, X_test_WITHOUT_outliers_baseCol = train_test_split(X_WITHOUT_outliers_baseCol, test_size = 0.2, random_state = 10)\n",
    "X_train_WITH_outliers_optCol, X_test_WITH_outliers_optCol, y_train, y_test = train_test_split(X_WITH_outliers_optCol, y, test_size = 0.2, random_state = 10)\n",
    "X_train_WITHOUT_outliers_optCol, X_test_WITHOUT_outliers_optCol = train_test_split(X_WITHOUT_outliers_optCol, test_size = 0.2, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization and MIN_MAX Scaling\n",
    "# X_train_WITH_outliers_baseCol \n",
    "# X_train_WITHOUT_outliers_baseCol \n",
    "# X_train_WITH_outliers_optCol\n",
    "# X_train_WITHOUT_outliers_optCol\n",
    "\n",
    "# WE NEED TO SAVE 3 OCCURRENCE: 1) DATASET PLANE (WITH NO CHANGES), 2) DATASET NORMALIZED, 3) DATASET MIN-MAX\n",
    "\n",
    "## NORMALIZATION\n",
    "### WITH OUTLIERS\n",
    "# Base Columns\n",
    "norm_WITH_outliers_baseCol = StandardScaler() # StandardScaler(), used to \"normalize\" or \"resize\" your data so that all your features are on the same scale.\n",
    "# .fit(), The \"Learning\"\n",
    "norm_WITH_outliers_baseCol.fit(X_train_WITH_outliers_baseCol) # Phase. the scaler (or model) looks at your data and calculates the necessary parameters. It does not change the data; it only learns from it.\n",
    "# Opt. Columns\n",
    "norm_WITH_outliers_optCol = StandardScaler()\n",
    "norm_WITH_outliers_optCol.fit(X_train_WITH_outliers_optCol)\n",
    "\n",
    "# .transform(), The \"Applying\" Phase.\n",
    "# NOTE: .fit_transform() — The \"Shortcut\" --> This is simply a convenience method that does both steps at the same time on the same piece of data. --- Use this on your Training Data ---\n",
    "# Base Columns\n",
    "X_train_WITH_outliers_baseCol_norm = norm_WITH_outliers_baseCol.transform(X_train_WITH_outliers_baseCol) # This uses the parameters calculated during .fit() to actually modify the data.\n",
    "X_train_WITH_outliers_baseCol_norm = pd.DataFrame(X_train_WITH_outliers_baseCol_norm, index = X_train_WITH_outliers_baseCol.index, columns = predictors_base) # We need to convert to DataFrame the transform with this variable\n",
    "X_test_WITH_outliers_baseCol_norm = norm_WITH_outliers_baseCol.transform(X_test_WITH_outliers_baseCol)\n",
    "X_test_WITH_outliers_baseCol_norm = pd.DataFrame(X_test_WITH_outliers_baseCol_norm, index = X_test_WITH_outliers_baseCol.index, columns = predictors_base)\n",
    "# Opt. Columns\n",
    "X_train_WITH_outliers_optCol_norm = norm_WITH_outliers_optCol.transform(X_train_WITH_outliers_optCol)\n",
    "X_train_WITH_outliers_optCol_norm = pd.DataFrame(X_train_WITH_outliers_optCol_norm, index = X_train_WITH_outliers_optCol.index, columns = predictors_opt)\n",
    "X_test_WITH_outliers_optCol_norm = norm_WITH_outliers_optCol.transform(X_test_WITH_outliers_optCol)\n",
    "X_test_WITH_outliers_optCol_norm = pd.DataFrame(X_test_WITH_outliers_optCol_norm, index = X_test_WITH_outliers_optCol.index, columns = predictors_opt)\n",
    "\n",
    "### WITHOUT OUTLIERS\n",
    "# Base Columns\n",
    "norm_WITHOUT_outliers_baseCol = StandardScaler()\n",
    "norm_WITHOUT_outliers_baseCol.fit(X_train_WITHOUT_outliers_baseCol)\n",
    "# Opt. Columns\n",
    "norm_WITHOUT_outliers_optCol = StandardScaler()\n",
    "norm_WITHOUT_outliers_optCol.fit(X_train_WITHOUT_outliers_optCol)\n",
    "# Base Columns\n",
    "X_train_WITHOUT_outliers_baseCol_norm = norm_WITHOUT_outliers_baseCol.transform(X_train_WITHOUT_outliers_baseCol)\n",
    "X_train_WITHOUT_outliers_baseCol_norm = pd.DataFrame(X_train_WITHOUT_outliers_baseCol_norm, index = X_train_WITHOUT_outliers_baseCol.index, columns = predictors_base)\n",
    "X_test_WITHOUT_outliers_baseCol_norm = norm_WITHOUT_outliers_baseCol.transform(X_test_WITHOUT_outliers_baseCol)\n",
    "X_test_WITHOUT_outliers_baseCol_norm = pd.DataFrame(X_test_WITHOUT_outliers_baseCol_norm, index = X_test_WITHOUT_outliers_baseCol.index, columns = predictors_base)\n",
    "# Opt. Columns\n",
    "X_train_WITHOUT_outliers_optCol_norm = norm_WITHOUT_outliers_optCol.transform(X_train_WITHOUT_outliers_optCol)\n",
    "X_train_WITHOUT_outliers_optCol_norm = pd.DataFrame(X_train_WITHOUT_outliers_optCol_norm, index = X_train_WITHOUT_outliers_optCol.index, columns = predictors_opt)\n",
    "X_test_WITHOUT_outliers_optCol_norm = norm_WITHOUT_outliers_optCol.transform(X_test_WITHOUT_outliers_optCol)\n",
    "X_test_WITHOUT_outliers_optCol_norm = pd.DataFrame(X_test_WITHOUT_outliers_optCol_norm, index = X_test_WITHOUT_outliers_optCol.index, columns = predictors_opt)\n",
    "\n",
    "\n",
    "## SCALED MIN_MAX\n",
    "### WITH OUTLIERS\n",
    "# Base Columns\n",
    "scaler_WITH_outliers_baseCol = MinMaxScaler() # MinMaxScaler() is a scaling technique that transforms the data so that all values fall within a specific range, most commonly between 0 and 1.\n",
    "scaler_WITH_outliers_baseCol.fit(X_train_WITH_outliers_baseCol)\n",
    "# Opt. Columns\n",
    "scaler_WITH_outliers_optCol = MinMaxScaler() # MinMaxScaler() is a scaling technique that transforms the data so that all values fall within a specific range, most commonly between 0 and 1.\n",
    "scaler_WITH_outliers_optCol.fit(X_train_WITH_outliers_optCol)\n",
    "# Base Columns\n",
    "X_train_WITH_outliers_baseCol_scal = scaler_WITH_outliers_baseCol.transform(X_train_WITH_outliers_baseCol)\n",
    "X_train_WITH_outliers_baseCol_scal = pd.DataFrame(X_train_WITH_outliers_baseCol_scal, index = X_train_WITH_outliers_baseCol.index, columns = predictors_base)\n",
    "X_test_WITH_outliers_baseCol_scal = scaler_WITH_outliers_baseCol.transform(X_test_WITH_outliers_baseCol)\n",
    "X_test_WITH_outliers_baseCol_scal = pd.DataFrame(X_test_WITH_outliers_baseCol_scal, index = X_test_WITH_outliers_baseCol.index, columns = predictors_base)\n",
    "# Opt. Columns\n",
    "X_train_WITH_outliers_optCol_scal = scaler_WITH_outliers_optCol.transform(X_train_WITH_outliers_optCol)\n",
    "X_train_WITH_outliers_optCol_scal = pd.DataFrame(X_train_WITH_outliers_optCol_scal, index = X_train_WITH_outliers_optCol.index, columns = predictors_opt)\n",
    "X_test_WITH_outliers_optCol_scal = scaler_WITH_outliers_optCol.transform(X_test_WITH_outliers_optCol)\n",
    "X_test_WITH_outliers_optCol_scal = pd.DataFrame(X_test_WITH_outliers_optCol_scal, index = X_test_WITH_outliers_optCol.index, columns = predictors_opt)\n",
    "\n",
    "### WITHOUT OUTLIERS\n",
    "# Base Columns\n",
    "scaler_WITHOUT_outliers_baseCol = MinMaxScaler()\n",
    "scaler_WITHOUT_outliers_baseCol.fit(X_train_WITHOUT_outliers_baseCol)\n",
    "# Opt. Columns\n",
    "scaler_WITHOUT_outliers_optCol = MinMaxScaler()\n",
    "scaler_WITHOUT_outliers_optCol.fit(X_train_WITHOUT_outliers_optCol)\n",
    "# Base Columns\n",
    "X_train_WITHOUT_outliers_baseCol_scal = scaler_WITHOUT_outliers_baseCol.transform(X_train_WITHOUT_outliers_baseCol)\n",
    "X_train_WITHOUT_outliers_baseCol_scal = pd.DataFrame(X_train_WITHOUT_outliers_baseCol_scal, index = X_train_WITHOUT_outliers_baseCol.index, columns = predictors_base)\n",
    "X_test_WITHOUT_outliers_baseCol_scal = scaler_WITHOUT_outliers_baseCol.transform(X_test_WITHOUT_outliers_baseCol)\n",
    "X_test_WITHOUT_outliers_baseCol_scal = pd.DataFrame(X_test_WITHOUT_outliers_baseCol_scal, index = X_test_WITHOUT_outliers_baseCol.index, columns = predictors_base)\n",
    "# Opt. Columns\n",
    "X_train_WITHOUT_outliers_optCol_scal = scaler_WITHOUT_outliers_optCol.transform(X_train_WITHOUT_outliers_optCol)\n",
    "X_train_WITHOUT_outliers_optCol_scal = pd.DataFrame(X_train_WITHOUT_outliers_optCol_scal, index = X_train_WITHOUT_outliers_optCol.index, columns = predictors_opt)\n",
    "X_test_WITHOUT_outliers_optCol_scal = scaler_WITHOUT_outliers_optCol.transform(X_test_WITHOUT_outliers_optCol)\n",
    "X_test_WITHOUT_outliers_optCol_scal = pd.DataFrame(X_test_WITHOUT_outliers_optCol_scal, index = X_test_WITHOUT_outliers_optCol.index, columns = predictors_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Testing Data Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table with train data modified WITH outliers and baseCol.\")\n",
    "print(tabulate(X_train_WITH_outliers_baseCol_norm.head(), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table with train data modified WITH outliers and optCol. Normalization of the data embedded.\")\n",
    "print(tabulate(X_train_WITHOUT_outliers_optCol_norm.head(), headers= \"keys\", tablefmt= \"psql\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Saving all of the DATASET\n",
    "    train, test with all the variance we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS that have been created so far in previous steps from the feature engineering\n",
    "# BaseCol\n",
    "X_train_WITH_outliers_baseCol.to_excel(\"../data/processed/X_train_WITH_outliers_baseCol.xlsx\", index = False)\n",
    "X_train_WITH_outliers_baseCol_norm.to_excel(\"../data/processed/X_train_WITH_outliers_baseCol_norm.xlsx\", index = False)\n",
    "X_train_WITH_outliers_baseCol_scal.to_excel(\"../data/processed/X_train_WITH_outliers_baseCol_scal.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_baseCol.to_excel(\"../data/processed/X_train_WITHOUT_outliers_baseCol.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_baseCol_norm.to_excel(\"../data/processed/X_train_WITHOUT_outliers_baseCol_norm.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_baseCol_scal.to_excel(\"../data/processed/X_train_WITHOUT_outliers_baseCol_scal.xlsx\", index = False)\n",
    "\n",
    "X_test_WITH_outliers_baseCol.to_excel(\"../data/processed/X_test_WITH_outliers_baseCol.xlsx\", index = False)\n",
    "X_test_WITH_outliers_baseCol_norm.to_excel(\"../data/processed/X_test_WITH_outliers_baseCol_norm.xlsx\", index = False)\n",
    "X_test_WITH_outliers_baseCol_scal.to_excel(\"../data/processed/X_test_WITH_outliers_baseCol_scal.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_baseCol.to_excel(\"../data/processed/X_test_WITHOUT_outliers_baseCol.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_baseCol_norm.to_excel(\"../data/processed/X_test_WITHOUT_outliers_baseCol_norm.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_baseCol_scal.to_excel(\"../data/processed/X_test_WITHOUT_outliers_baseCol_scal.xlsx\", index = False)\n",
    "\n",
    "# OptCol\n",
    "X_train_WITH_outliers_optCol.to_excel(\"../data/processed/X_train_WITH_outliers_optCol.xlsx\", index = False)\n",
    "X_train_WITH_outliers_optCol_norm.to_excel(\"../data/processed/X_train_WITH_outliers_optCol_norm.xlsx\", index = False)\n",
    "X_train_WITH_outliers_optCol_scal.to_excel(\"../data/processed/X_train_WITH_outliers_optCol_scal.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_optCol.to_excel(\"../data/processed/X_train_WITHOUT_outliers_optCol.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_optCol_norm.to_excel(\"../data/processed/X_train_WITHOUT_outliers_optCol_norm.xlsx\", index = False)\n",
    "X_train_WITHOUT_outliers_optCol_scal.to_excel(\"../data/processed/X_train_WITHOUT_outliers_optCol_scal.xlsx\", index = False)\n",
    "\n",
    "X_test_WITH_outliers_optCol.to_excel(\"../data/processed/X_test_WITH_outliers_optCol.xlsx\", index = False)\n",
    "X_test_WITH_outliers_optCol_norm.to_excel(\"../data/processed/X_test_WITH_outliers_optCol_norm.xlsx\", index = False)\n",
    "X_test_WITH_outliers_optCol_scal.to_excel(\"../data/processed/X_test_WITH_outliers_optCol_scal.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_optCol.to_excel(\"../data/processed/X_test_WITHOUT_outliers_optCol.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_optCol_norm.to_excel(\"../data/processed/X_test_WITHOUT_outliers_optCol_norm.xlsx\", index = False)\n",
    "X_test_WITHOUT_outliers_optCol_scal.to_excel(\"../data/processed/X_test_WITHOUT_outliers_optCol_scal.xlsx\", index = False)\n",
    "\n",
    "y_train.to_excel(\"../data/processed/y_train.xlsx\", index = False)\n",
    "y_test.to_excel(\"../data/processed/y_test.xlsx\", index = False)\n",
    "\n",
    "# SCALERS --> Saving the models\n",
    "\n",
    "with open(\"../models/norm_WITH_outliers_baseCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(norm_WITH_outliers_baseCol, file)\n",
    "with open(\"../models/norm_WITH_outliers_optCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(norm_WITH_outliers_optCol, file)\n",
    "with open(\"../models/norm_WITHOUT_outliers_baseCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(norm_WITHOUT_outliers_baseCol, file)\n",
    "with open(\"../models/norm_WITHOUT_outliers_optCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(norm_WITHOUT_outliers_optCol, file)\n",
    "with open(\"../models/scaler_WITH_outliers_baseCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(scaler_WITH_outliers_baseCol, file)\n",
    "with open(\"../models/scaler_WITH_outliers_optCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(scaler_WITH_outliers_optCol, file)\n",
    "with open(\"../models/scaler_WITHOUT_outliers_baseCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(scaler_WITHOUT_outliers_baseCol, file)\n",
    "with open(\"../models/scaler_WITHOUT_outliers_optCol.pkl\", \"wb\") as file:\n",
    "  pickle.dump(scaler_WITHOUT_outliers_optCol, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7. Feature Selection\n",
    "    - Test all dataset \"roughly\" and I will keep the best score. Keeping all variable.\n",
    "    - The model need to be trained entirely.\n",
    "    - If results meet desire objective --> YEAH! WE?VE FINISHED.\n",
    "    - If not, move back to step 6 and repeat the process from step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **IMPORTANT MESSAGE**: \n",
    "- Although I have runned the feature selection to check best freatures or variable using SelectKBest, I will run my KNN model with the base al optimized columns define before to compare Accuracy\n",
    "- For a better training an practicing and checking if the Accuracy of the KNN model cqan be improved, I might go back to this point of feature selection and try running the model with SelectKBest.\n",
    "- Thank you all for your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8. Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_base = [\n",
    "    X_train_WITH_outliers_baseCol,\n",
    "    X_train_WITH_outliers_baseCol_norm,\n",
    "    X_train_WITH_outliers_baseCol_scal,\n",
    "    X_train_WITHOUT_outliers_baseCol,\n",
    "    X_train_WITHOUT_outliers_baseCol_norm,\n",
    "    X_train_WITHOUT_outliers_baseCol_scal,\n",
    "    ]\n",
    "\n",
    "datasets_opt = [\n",
    "    X_train_WITH_outliers_optCol,\n",
    "    X_train_WITH_outliers_optCol_norm,\n",
    "    X_train_WITH_outliers_optCol_scal,\n",
    "    X_train_WITHOUT_outliers_optCol,\n",
    "    X_train_WITHOUT_outliers_optCol_norm,\n",
    "    X_train_WITHOUT_outliers_optCol_scal,\n",
    "    ]\n",
    "\n",
    "models_base = []\n",
    "metrics_base = []\n",
    "for dataset in datasets_base:\n",
    "  model = KNeighborsClassifier() # KNN model\n",
    "  model.fit(dataset, y_train) # To train the model\n",
    "  y_pred = model.predict(dataset)\n",
    "  metric = accuracy_score(y_train, y_pred)\n",
    "  metrics_base.append(metric)\n",
    "  models_base.append(model)\n",
    "\n",
    "best_metric_base = max(metrics_base)\n",
    "best_index_base = metrics_base.index(best_metric_base)\n",
    "print(f\"This is the list of accu. score: {metrics_base}\\nThe best metric: {best_metric_base}\\nThe Best index: {best_index_base}\")\n",
    "print(\"The best DataSet is: \", datasets_base[best_index_base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models_opt = []\n",
    "metrics_opt = []\n",
    "for dataset in datasets_opt:\n",
    "  model = KNeighborsClassifier()\n",
    "  model.fit(dataset, y_train) # To train the model\n",
    "  y_pred = model.predict(dataset)\n",
    "  metric = accuracy_score(y_train, y_pred)\n",
    "  metrics_opt.append(metric)\n",
    "  models_opt.append(model)\n",
    "\n",
    "best_metric_opt = max(metrics_opt)\n",
    "best_index_opt = metrics_opt.index(best_metric_opt)\n",
    "print(f\"This is the list of accu. score: {metrics_opt}\\nThe best metric: {best_metric_opt}\\nThe Best index: {best_index_opt}\")\n",
    "print(\"The best DataSet is: \", datasets_opt[best_index_opt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Evaluate Performance on the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Using the 'Champion' data (Index 4 for base from the list)\n",
    "# Let's assume you're using the Normalized (StandardScaler) version\n",
    "knn_base = KNeighborsClassifier()\n",
    "knn_base.fit(X_train_WITHOUT_outliers_baseCol_norm, y_train)\n",
    "\n",
    "# 2. Predict on the unseen Test Set\n",
    "y_pred_base = knn_base.predict(X_test_WITHOUT_outliers_baseCol_norm)\n",
    "\n",
    "# 3. Create the Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_base)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= ['Low Quality', 'High Quality'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap= 'Blues')\n",
    "plt.title('Model with base Columns selection: Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4. Detailed Report\n",
    "print(classification_report(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Using the 'Champion' data (Index 2 for optimized from the list)\n",
    "knn_opt = KNeighborsClassifier()\n",
    "knn_opt.fit(X_train_WITH_outliers_optCol_scal, y_train)\n",
    "\n",
    "# 2. Predict on the unseen Test Set\n",
    "y_pred_opt = knn_opt.predict(X_test_WITH_outliers_optCol_scal)\n",
    "\n",
    "# 3. Create the Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_opt)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels= ['Low Quality', 'High Quality'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(8, 6))\n",
    "disp.plot(cmap= 'Blues')\n",
    "plt.title('Model with optimized Columns selection: Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# 4. Detailed Report\n",
    "print(classification_report(y_test, y_pred_opt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9. Optimize k.\n",
    "- Create a loop to test different k values (e.g., from 1 to 20)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize lists to store our results\n",
    "k_values = range(1, 21, 2) # Testing 1, 3, 5, ..., 19\n",
    "accuracies = []\n",
    "\n",
    "# 2. The Loop\n",
    "for k in k_values:\n",
    "    # Initialize model with current k\n",
    "    knn = KNeighborsClassifier(n_neighbors= k)\n",
    "    \n",
    "    # Fit using the best training data\n",
    "    knn.fit(X_train_WITH_outliers_optCol_scal, y_train)\n",
    "    \n",
    "    # Predict and calculate accuracy\n",
    "    y_pred = knn.predict(X_test_WITH_outliers_optCol_scal)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Save the result\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Find the best K and its accuracy\n",
    "best_acc = max(accuracies)\n",
    "best_k = k_values[accuracies.index(best_acc)]\n",
    "\n",
    "print(f\"The optimal value is k = {best_k} with an accuracy of {best_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Plot Accuracy vs k (Find the best value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, accuracies, color= 'blue', linestyle= 'dashed', marker= 'o', markerfacecolor= 'red', markersize= 8)\n",
    "\n",
    "plt.title('Accuracy Score vs. K Value (Optimized Dataset)')\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')\n",
    "plt.xticks(k_values)\n",
    "plt.grid(True, linestyle= '--', alpha= 0.7)\n",
    "\n",
    "# Highlight the best K. For more info--> https://matplotlib.org/stable/gallery/text_labels_and_annotations/annotation_basic.html\n",
    "plt.annotate(f'Best K: {best_k}', xy= (best_k, best_acc), xytext= (best_k+1, best_acc), arrowprops= dict(facecolor= 'black', shrink= 0.05))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1.1 Conclusion on K Value Chart\n",
    "- To optimize the model, I tested $k$ values from 1 to 20.\n",
    "- The K Value range I have adjusted the step to \"2\" avoiding having tight voting when the number is even.\n",
    "- The results indicate that $k=17$ is the optimal hyperparameter. \n",
    "- Beyond this point, accuracy declines as the model begins to underfit, incorporating irrelevant neighbors into the classification decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final \"Champion\" Model\n",
    "final_knn = KNeighborsClassifier(n_neighbors= 17)\n",
    "final_knn.fit(X_train_WITH_outliers_optCol_scal, y_train)\n",
    "\n",
    "y_pred_final = final_knn.predict(X_test_WITH_outliers_optCol_scal)\n",
    "\n",
    "print(f\"Final Optimized Accuracy with k=17: {accuracy_score(y_test, y_pred_final):.4f}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Save the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the KNN Model\n",
    "with open(\"../models/champion_knn_model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(final_knn, file)\n",
    "\n",
    "print(\"Champion Model and Scaler have been saved to the /models/ folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10. Feeling Confident (test the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_wine_quality(input_list):\n",
    "    \"\"\" Takes 11 raw features, engineers 'total_acidity', selects the best features, and predicts.   \"\"\"\n",
    "    # 1. I will map the 11 inputs to column names\n",
    "    all_cols = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', \n",
    "                'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', \n",
    "                'density', 'pH', 'sulphates', 'alcohol']\n",
    "    \n",
    "    df_input = pd.DataFrame([input_list], columns= all_cols)\n",
    "    \n",
    "    # 2. FEATURE ENGINEERING: Recreate 'total_acidity' as I did in the EDA\n",
    "    # This must match exactly how I did it during training\n",
    "    df_input['total_acidity'] = (df_input['fixed acidity'] + \n",
    "                                 df_input['volatile acidity'] + \n",
    "                                 df_input['citric acid'])\n",
    "    \n",
    "    # 3. I select the Top 5 Winning Columns\n",
    "    winning_cols = ['total_acidity', 'total sulfur dioxide', 'chlorides', 'sulphates', 'alcohol']\n",
    "    df_final = df_input[winning_cols]\n",
    "    \n",
    "    # 4. SCALE the data using the Champion Scaler (MinMax) saved before\n",
    "    X_scaled = scaler_WITH_outliers_optCol.transform(df_final)\n",
    "    X_scaled = pd.DataFrame(X_scaled, index= df_final.index, columns= winning_cols)\n",
    "    \n",
    "    # 5. VAMOSS!! PREDICT\n",
    "    prediction = final_knn.predict(X_scaled)[0]\n",
    "    \n",
    "    # 6. RETURN Result\n",
    "    if prediction == 1:\n",
    "        return \"This wine is likely of HIGH quality! 🍷✨\"\n",
    "    else:\n",
    "        return \"This wine is likely of medium/low quality. 🍷\"\n",
    "\n",
    "# --- TEST ---\n",
    "# Standard wine input (11 values) as per 4GeeksAcademy\n",
    "test_wine = [7.4, 0.7, 0.0, 1.9, 0.076, 11.0, 34.0, 0.9978, 3.51, 0.56, 9.4]\n",
    "print(predict_wine_quality(test_wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
